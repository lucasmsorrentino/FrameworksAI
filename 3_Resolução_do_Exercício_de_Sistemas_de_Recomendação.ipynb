{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasmsorrentino/FrameworksAI/blob/main/3_Resolu%C3%A7%C3%A3o_do_Exerc%C3%ADcio_de_Sistemas_de_Recomenda%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Resolução do Exercício de Sistemas de Recomendação\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uRp8mmEtSBfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CÓDIGO FINAL E ROBUSTO (LIVROS)\n",
        "# ==========================================\n",
        "\n",
        "# 1. SETUP DO AMBIENTE (LEGACY)\n",
        "!pip install -q tensorflow-recommenders\n",
        "import os\n",
        "# OBRIGATÓRIO: Forçar Keras 2 antes de importar TensorFlow\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "print(f\"Versão TF: {tf.__version__}\")\n",
        "\n",
        "# 2. CARREGAMENTO E CORREÇÃO DOS DADOS\n",
        "print(\"\\n=== A CARREGAR DADOS ===\")\n",
        "\n",
        "# Procura o ficheiro automaticamente\n",
        "files = [f for f in os.listdir() if 'Base_livros' in f and not f.endswith('.csv')] # Prioriza Excel\n",
        "if not files:\n",
        "    # Se não achar Excel, tenta CSV\n",
        "    files = [f for f in os.listdir() if 'Base_livros' in f]\n",
        "\n",
        "if not files:\n",
        "    raise FileNotFoundError(\"❌ ERRO: Ficheiro 'Base_livros' não encontrado. Faça upload!\")\n",
        "\n",
        "filename = files[0]\n",
        "print(f\"-> A ler: {filename}\")\n",
        "\n",
        "try:\n",
        "    # Tenta ler o ficheiro\n",
        "    if filename.endswith('.xlsx'):\n",
        "        df = pd.read_excel(filename)\n",
        "    else:\n",
        "        df = pd.read_csv(filename, on_bad_lines='skip')\n",
        "\n",
        "    # --- DIAGNÓSTICO DE COLUNAS ---\n",
        "    print(f\"-> Colunas detetadas inicialmente: {df.columns.tolist()}\")\n",
        "\n",
        "    # --- CORREÇÃO DE FORMATO \"AGLOMERADO\" ---\n",
        "    # Verifica se a primeira coluna contém vírgulas no nome (sinal de CSV mal formatado)\n",
        "    primeira_coluna = df.columns[0]\n",
        "\n",
        "    # Se 'ID_usuario' NÃO existe, mas a 1ª coluna parece conter os dados misturados...\n",
        "    if 'ID_usuario' not in df.columns and ',' in str(primeira_coluna):\n",
        "        print(\"⚠️ Detetado formato misturado (CSV dentro de Excel). A corrigir à força...\")\n",
        "\n",
        "        # Pega os nomes corretos do cabeçalho \"ISBN,Titulo,Autor...\"\n",
        "        novos_nomes = str(primeira_coluna).replace('\"', '').split(',')\n",
        "\n",
        "        # Separa a primeira coluna pelos dados\n",
        "        df_split = df.iloc[:, 0].astype(str).str.split(',', expand=True)\n",
        "\n",
        "        # Garante que não temos colunas a mais\n",
        "        if df_split.shape[1] > len(novos_nomes):\n",
        "            df_split = df_split.iloc[:, :len(novos_nomes)]\n",
        "\n",
        "        # Atribui os nomes\n",
        "        df_split.columns = novos_nomes\n",
        "        df = df_split\n",
        "        print(\"✅ Correção aplicada com sucesso!\")\n",
        "\n",
        "    # Limpeza final de nomes (remove espaços extras)\n",
        "    df.columns = df.columns.astype(str).str.strip()\n",
        "\n",
        "    # --- VERIFICAÇÃO FINAL ---\n",
        "    if 'ID_usuario' not in df.columns:\n",
        "        print(\"\\n❌ ERRO CRÍTICO: As colunas ainda estão erradas.\")\n",
        "        print(f\"O Python está a ler isto: {df.columns.tolist()}\")\n",
        "        print(\"Tente converter o seu Excel para CSV 'verdadeiro' no Excel (Salvar Como > CSV UTF-8).\")\n",
        "        raise KeyError(\"Coluna ID_usuario não encontrada\")\n",
        "\n",
        "    # Limpeza dos valores\n",
        "    df['ID_usuario'] = df['ID_usuario'].astype(str).str.replace('\"', '').str.strip()\n",
        "    df['Titulo'] = df['Titulo'].astype(str).str.replace('\"', '').str.strip()\n",
        "\n",
        "    print(\"✅ Dados prontos!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ocorreu um erro na leitura: {e}\")\n",
        "    raise\n",
        "\n",
        "# 3. PREPARAR MODELO\n",
        "print(\"\\n=== A TREINAR MODELO ===\")\n",
        "\n",
        "data = df[['ID_usuario', 'Titulo']]\n",
        "ratings_ds = tf.data.Dataset.from_tensor_slices(dict(data))\n",
        "books_ds = tf.data.Dataset.from_tensor_slices(data['Titulo'].unique())\n",
        "\n",
        "ratings_ds = ratings_ds.map(lambda x: {\"user_id\": x[\"ID_usuario\"], \"book_title\": x[\"Titulo\"]})\n",
        "\n",
        "# Vocabulários\n",
        "user_lookup = tf.keras.layers.StringLookup(mask_token=None)\n",
        "user_lookup.adapt(ratings_ds.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "book_lookup = tf.keras.layers.StringLookup(mask_token=None)\n",
        "book_lookup.adapt(books_ds)\n",
        "\n",
        "num_users = user_lookup.vocabulary_size()\n",
        "num_books = book_lookup.vocabulary_size()\n",
        "print(f\"-> {num_users} usuários e {num_books} livros.\")\n",
        "\n",
        "# Classes do Modelo (Customizadas para estabilidade)\n",
        "class UserTower(tf.keras.Model):\n",
        "    def __init__(self, lookup, vocab_size, emb_dim=32):\n",
        "        super().__init__()\n",
        "        self.lookup = lookup\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
        "    def call(self, inputs):\n",
        "        return self.embedding(self.lookup(inputs))\n",
        "\n",
        "class BookTower(tf.keras.Model):\n",
        "    def __init__(self, lookup, vocab_size, emb_dim=32):\n",
        "        super().__init__()\n",
        "        self.lookup = lookup\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
        "    def call(self, inputs):\n",
        "        return self.embedding(self.lookup(inputs))\n",
        "\n",
        "class BookRecModel(tfrs.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.user_model = UserTower(user_lookup, num_users)\n",
        "        self.book_model = BookTower(book_lookup, num_books)\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=books_ds.batch(128).map(self.book_model)\n",
        "            )\n",
        "        )\n",
        "    def compute_loss(self, features, training=False):\n",
        "        u = self.user_model(features[\"user_id\"])\n",
        "        b = self.book_model(features[\"book_title\"])\n",
        "        return self.task(u, b)\n",
        "\n",
        "# Treinar\n",
        "model = BookRecModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "model.fit(ratings_ds.batch(4096).cache(), epochs=3)\n",
        "\n",
        "# 4. TESTAR\n",
        "print(\"\\n=== RESULTADO ===\")\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((books_ds.batch(100), books_ds.batch(100).map(model.book_model)))\n",
        ")\n",
        "\n",
        "test_user = '276725'\n",
        "print(f\"Top 3 sugestões para o usuário {test_user}:\")\n",
        "_, titles = index(np.array([test_user]))\n",
        "for i, title in enumerate(titles[0, :3]):\n",
        "    print(f\"{i+1}: {title.numpy().decode('utf-8')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZW8M_nHgCJV",
        "outputId": "25dcdac3-f6ed-44fd-b0b3-1a6a5e0c0de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão TF: 2.19.0\n",
            "\n",
            "=== A CARREGAR DADOS ===\n",
            "-> A ler: Base_livros.xlsx\n",
            "-> Colunas detetadas inicialmente: ['ISBN,Titulo,Autor,Ano,Editora,ID_usuario,Notas', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
            "⚠️ Detetado formato misturado (CSV dentro de Excel). A corrigir à força...\n",
            "✅ Correção aplicada com sucesso!\n",
            "✅ Dados prontos!\n",
            "\n",
            "=== A TREINAR MODELO ===\n",
            "-> 13857 usuários e 115215 livros.\n",
            "Epoch 1/3\n",
            "32/32 [==============================] - 756s 24s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 4.4242e-04 - factorized_top_k/top_10_categorical_accuracy: 6.4422e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0013 - factorized_top_k/top_100_categorical_accuracy: 0.0016 - loss: 32853.9503 - regularization_loss: 0.0000e+00 - total_loss: 32853.9503\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 665s 20s/step - factorized_top_k/top_1_categorical_accuracy: 6.2093e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0057 - factorized_top_k/top_50_categorical_accuracy: 0.0152 - factorized_top_k/top_100_categorical_accuracy: 0.0245 - loss: 32668.9263 - regularization_loss: 0.0000e+00 - total_loss: 32668.9263\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 676s 20s/step - factorized_top_k/top_1_categorical_accuracy: 4.5794e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0056 - factorized_top_k/top_10_categorical_accuracy: 0.0082 - factorized_top_k/top_50_categorical_accuracy: 0.0171 - factorized_top_k/top_100_categorical_accuracy: 0.0300 - loss: 31657.5137 - regularization_loss: 0.0000e+00 - total_loss: 31657.5137\n",
            "\n",
            "=== RESULTADO ===\n",
            "Top 3 sugestões para o usuário 276725:\n",
            "1: Men Are from Mars\n",
            "2: Shattered Trust (Harlequin Presents\n",
            "3: Sudden Fire (Postcards From Europe) (Harlequin Presents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "1. Desempenho do Modelo O modelo foi treinado com sucesso numa base de dados\n",
        "considerável (13.857 usuários e 115.215 livros).\n",
        "    * Convergência: Observamos que a perda (loss) diminuiu progressivamente ao longo das 3 épocas (de 32853 para 31657), o que prova que a rede neural aprendeu padrões de associação entre leitores e livros.\n",
        "    * Precisão: A métrica top_100_categorical_accuracy subiu para cerca de 3% (0.0300). Embora pareça um número baixo, num universo de 115 mil livros possíveis, o modelo conseguir colocar o livro \"correto\" entre os 100 primeiros em 3% das vezes (após apenas 3 épocas de treino) demonstra que o sistema de Retrieval (Recuperação) está a funcionar muito melhor que um sorteio aleatório.\n",
        "\n",
        "    \n",
        "\n",
        "2. As Recomendações para o Usuário 276725 O sistema sugeriu os seguintes livros:\n",
        "\n",
        "    1.   Men Are from Mars... (Homens são de Marte...) - Clássico de\n",
        "    2.   Shattered Trust (Harlequin Presents) - Romance.\n",
        "    3.   Sudden Fire (Harlequin Presents) - Romance.\n",
        "<br>\n",
        "\n",
        "> Interpretação: O modelo identificou um padrão de preferência claro. O sistema agrupou este utilizador no espaço vetorial próximo de livros de romance e relacionamentos (notável pela presença da editora Harlequin, famosa por romances de banca). Isto indica que a \"Torre do Usuário\" e a \"Torre do Livro\" conseguiram alinhar corretamente os vetores de gosto literário."
      ],
      "metadata": {
        "id": "PqLJSkf8s5Ud"
      }
    }
  ]
}